{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import instructor\n",
    "import openai\n",
    "from burr.core import Application, ApplicationBuilder, State, action, expr, when\n",
    "from burr.tracking import LocalTrackingClient\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from dreamai.ai import ModelName, assistant_message, system_message, user_message\n",
    "\n",
    "ask_oai = instructor.from_openai(openai.OpenAI())\n",
    "ask_gemini = instructor.from_gemini(\n",
    "    client=genai.GenerativeModel(model_name=ModelName.GEMINI_FLASH),\n",
    "    mode=instructor.Mode.GEMINI_JSON,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLARIFICATION_QUESTIONS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClarificationQuestions(BaseModel):\n",
    "    questions: list[str] = Field(\n",
    "        description=\"Clarification Questions\", default_factory=list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@action(reads=[], writes=[\"incoming_email\", \"response_instructions\"])\n",
    "def process_input(\n",
    "    state: State, email_to_respond: str, response_instructions: str\n",
    ") -> State:\n",
    "    return state.update(\n",
    "        incoming_email=email_to_respond, response_instructions=response_instructions\n",
    "    )\n",
    "\n",
    "\n",
    "@action(\n",
    "    reads=[\"response_instructions\", \"incoming_email\"],\n",
    "    writes=[\"clarification_questions\"],\n",
    ")\n",
    "def ask_for_clarifications(state: State) -> State:\n",
    "    incoming_email = state[\"incoming_email\"]\n",
    "    response_instructions = state[\"response_instructions\"]\n",
    "    system = \"You are a chatbot that has the task of generating responses to an email on behalf of a user.\"\n",
    "    task = f\"\"\"\\\n",
    "The email you are to respond to is: {incoming_email}.\n",
    "Your instructions are: {response_instructions}.\n",
    "Your first task is to ask any clarifying questions for the user who is asking you to respond to this email.\n",
    "These clarifying questions are for the user, *not* for the original sender of the email.\n",
    "Please generate a list of at MOST {NUM_CLARIFICATION_QUESTIONS} questions (and you really can do less, or even none are OK!)\n",
    "But only if you feel that you could leverage that clarification (my time is valuable).\n",
    "If you do not need clarification, return an empty list.\n",
    "\"\"\"\n",
    "    try:\n",
    "        questions = ask_gemini.create(\n",
    "            response_model=ClarificationQuestions,\n",
    "            messages=[system_message(system), user_message(task.strip())],  # type: ignore\n",
    "        )\n",
    "        if not isinstance(questions, ClarificationQuestions):\n",
    "            questions = ClarificationQuestions()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        questions = ClarificationQuestions()\n",
    "    return state.update(\n",
    "        clarification_questions=questions.questions[:NUM_CLARIFICATION_QUESTIONS]\n",
    "    )\n",
    "\n",
    "\n",
    "@action(reads=[], writes=[\"clarification_answers\"])\n",
    "def answer_clarifications(state: State, clarification_answers: list[str]) -> State:\n",
    "    \"\"\"Clarifies the response instructions if needed.\"\"\"\n",
    "    return state.update(clarification_answers=clarification_answers)\n",
    "\n",
    "\n",
    "@action(\n",
    "    reads=[\n",
    "        \"incoming_email\",\n",
    "        \"response_instructions\",\n",
    "        \"clarification_answers\",\n",
    "        \"clarification_questions\",\n",
    "        \"draft_history\",\n",
    "        \"feedback\",\n",
    "    ],\n",
    "    writes=[\"current_draft\", \"draft_history\"],\n",
    ")\n",
    "def formulate_draft(state: State) -> tuple[dict, State]:\n",
    "    \"\"\"Formulates the draft response based on the incoming email, response instructions, and any clarifications.\"\"\"\n",
    "    incoming_email = state[\"incoming_email\"]\n",
    "    response_instructions = state[\"response_instructions\"]\n",
    "    clarification_answers_formatted_q_a = \"\\n\".join(\n",
    "        [\n",
    "            f\"Q: {q}\\nA: {a}\"\n",
    "            for q, a in zip(\n",
    "                state[\"clarification_questions\"], state.get(\"clarification_answers\", [])\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    system = \"You are a chatbot that has the task of generating responses to an email.\"\n",
    "    task = f\"\"\"\\\n",
    "The email you are to respond to is: {incoming_email}\n",
    "Your instructions are: {response_instructions}\n",
    "You have already asked the following questions and received the following answers:\n",
    "{clarification_answers_formatted_q_a}\n",
    "\"\"\"\n",
    "    if state[\"draft_history\"]:\n",
    "        task += \"\\nYour previous draft was: \" + state[\"draft_history\"][-1]\n",
    "        task += \"\\nFeedback received: \" + state[\"feedback\"]\n",
    "        task += \"\\nPlease incorporate this feedback into your response.\"\n",
    "    task += \"\\nPlease generate a draft response using all this information!\"\n",
    "    messages = [system_message(system), user_message(task.strip())]\n",
    "    try:\n",
    "        draft = ask_gemini.create(\n",
    "            response_model=str,\n",
    "            messages=messages,  # type: ignore\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        draft = \"\"\n",
    "    return {\"prompt\": task, \"current_draft\": draft}, state.update(\n",
    "        current_draft=draft\n",
    "    ).append(draft_history=draft)\n",
    "\n",
    "\n",
    "@action(reads=[], writes=[\"feedback\", \"feedback_history\"])\n",
    "def process_feedback(state: State, feedback: str) -> tuple[dict, State]:\n",
    "    \"\"\"Processes feedback from user and updates state with the feedback.\"\"\"\n",
    "    result = {\"feedback\": feedback}\n",
    "    return result, state.update(feedback=feedback).append(feedback_history=feedback)\n",
    "\n",
    "\n",
    "@action(reads=[\"current_draft\", \"feedback\"], writes=[\"final_draft\"])\n",
    "def final_result(state: State) -> tuple[dict, State]:\n",
    "    \"\"\"Returns the final result of the process.\"\"\"\n",
    "    result = {\"final_draft\": state[\"current_draft\"]}\n",
    "    return result, state.update(final_draft=result[\"final_draft\"])\n",
    "\n",
    "\n",
    "def application(\n",
    "    app_id: str = \"dai_email\",\n",
    "    username: str = \"hamza_email\",\n",
    "    project: str = \"email_assistant\",\n",
    ") -> Application:\n",
    "    tracker = LocalTrackingClient(project=project)\n",
    "    builder = (\n",
    "        ApplicationBuilder()\n",
    "        .with_actions(\n",
    "            process_input,\n",
    "            ask_for_clarifications,\n",
    "            answer_clarifications,\n",
    "            formulate_draft,\n",
    "            process_feedback,\n",
    "            final_result,\n",
    "        )\n",
    "        .with_transitions(\n",
    "            (\"process_input\", \"ask_for_clarifications\"),\n",
    "            (\n",
    "                \"ask_for_clarifications\",\n",
    "                \"answer_clarifications\",\n",
    "                expr(\"len(clarification_questions) > 0\"),  # type: ignore\n",
    "            ),\n",
    "            (\"ask_for_clarifications\", \"formulate_draft\"),\n",
    "            (\"answer_clarifications\", \"formulate_draft\"),\n",
    "            (\"formulate_draft\", \"process_feedback\"),\n",
    "            (\"process_feedback\", \"formulate_draft\", expr(\"len(feedback) > 0\")),  # type: ignore\n",
    "            (\"process_feedback\", \"final_result\"),\n",
    "        )\n",
    "        .with_tracker(\"local\", project=project)\n",
    "        .with_identifiers(app_id=app_id, partition_key=username)\n",
    "        .initialize_from(\n",
    "            tracker,\n",
    "            resume_at_next_action=True,\n",
    "            default_state={\"draft_history\": [], \"feedback_history\": []},\n",
    "            default_entrypoint=\"process_input\",\n",
    "        )\n",
    "    )\n",
    "    return builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL = \"\"\"\\\n",
    "Hi Hamza,\n",
    "\n",
    "I hope you are well.\n",
    "\n",
    "I have made a cool tool called DreamAI for AI practitioners. I am reaching out to you to see if you would be interested in trying it out.\n",
    "\n",
    "Please inform me of your availability for a quick chat. I look forward to your kind response.\n",
    "\n",
    "Regards,\n",
    "Rafay\"\"\"\n",
    "\n",
    "INSTRUCTIONS = \"\"\"\\\n",
    "I get a bunch of these emails and usually ignore them.\n",
    "I don't want to be rude, but I also don't want to waste my time. But also, I don't want to miss out on something cool.\n",
    "Can you help me craft a response that is polite and respectful, but also sets the right expectations?\n",
    "And you never know, maybe I will actually try out the tool if it is cool enough. I need some more details to make that decision.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = application(app_id=None)\n",
    "app.visualize(\n",
    "    output_file_path=\"statemachine\",\n",
    "    include_conditions=True,\n",
    "    include_state=True,\n",
    "    format=\"png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_answers(questions: list[str]) -> list[str]:\n",
    "    \"\"\"Requests answers from the user for the questions the LLM has\"\"\"\n",
    "    answers = []\n",
    "    print(\"The email assistant wants more information:\\n\")\n",
    "    for question in questions:\n",
    "        answers.append(input(question))\n",
    "    return answers\n",
    "\n",
    "\n",
    "def request_feedback(draft: str) -> str:\n",
    "    \"\"\"Requests feedback from the user for a draft\"\"\"\n",
    "    print(\n",
    "        f\"here's a draft!: \\n {draft} \\n \\n What feedback do you have?\",\n",
    "        \"If you have no feedback then we'll finish it up.\",\n",
    "    )\n",
    "    return input(\"Write feedback or leave blank to continue (if you're happy)\")\n",
    "\n",
    "\n",
    "inputs = {\"email_to_respond\": EMAIL, \"response_instructions\": INSTRUCTIONS}\n",
    "while True:\n",
    "    action, result, state = app.run(\n",
    "        halt_before=[\"answer_clarifications\", \"process_feedback\"],\n",
    "        halt_after=[\"final_result\"],\n",
    "        inputs=inputs,\n",
    "    )\n",
    "    if action.name == \"answer_clarifications\":\n",
    "        questions = state[\"clarification_questions\"]\n",
    "        answers = request_answers(questions)\n",
    "        inputs = {\"clarification_answers\": answers}\n",
    "    if action.name == \"process_feedback\":\n",
    "        feedback = request_feedback(state[\"current_draft\"])\n",
    "        inputs = {\"feedback\": feedback}\n",
    "    if action.name == \"final_result\":\n",
    "        print(\"final result is:\", state[\"current_draft\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"final_draft\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
