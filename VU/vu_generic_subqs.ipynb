{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Annotated\n",
    "\n",
    "import anthropic\n",
    "import instructor\n",
    "import openai\n",
    "from chromadb import Collection as ChromaCollection\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import AfterValidator, BaseModel, Field, ValidationInfo, model_validator\n",
    "from tenacity import RetryError, Retrying, stop_after_attempt, wait_random_exponential\n",
    "\n",
    "from dreamai.ai import ModelName, system_message, user_message\n",
    "from dreamai.chroma import chroma_collection, query_collection, traverse_ids\n",
    "from dreamai.pdf import pdf_to_collection\n",
    "from dreamai.utils import deindent\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ask_oai = instructor.from_openai(openai.OpenAI())\n",
    "ask_cld = instructor.from_anthropic(anthropic.Anthropic())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# data_dir = Path(\"/media/hamza/data2/MATH/train/\")\n",
    "# questions_dir = Path(\"math_102_questions\")\n",
    "# question_id = 0\n",
    "# for folder in data_dir.iterdir():\n",
    "#     if folder.is_dir() and folder.name != \"counting_and_probability\":\n",
    "#         folder_questions = []\n",
    "#         for question_file in folder.glob(\"*.json\"):\n",
    "#             question = json.loads(question_file.read_text())\n",
    "#             if \"5\" in question[\"level\"]:\n",
    "#                 dest = questions_dir / f\"{folder.name}/{question_id}.json\"\n",
    "#                 os.makedirs(dest.parent, exist_ok=True)\n",
    "#                 with open(dest, \"w\") as f:\n",
    "#                     json.dump(\n",
    "#                         {\n",
    "#                             \"id\": str(question_id),\n",
    "#                             \"problem\": question[\"problem\"],\n",
    "#                             \"solution\": question[\"solution\"],\n",
    "#                         },\n",
    "#                         f,\n",
    "#                         indent=2,\n",
    "#                     )\n",
    "#                 question_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "MODEL = ModelName.GPT_3\n",
    "MAX_TOKENS = 1500\n",
    "CONCEPT_WORD_COUNT = 3\n",
    "QUESTIONS_PER_FOLDER = 40\n",
    "ATTEMPTS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def validate_word_count(text: str, word_count: int = 3, text_name: str = \"Text\") -> str:\n",
    "    if len(text.split()) < word_count:\n",
    "        raise ValueError(f\"{text_name} should be at least {word_count} words long\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def validate_topic_subtopic(cls, info: ValidationInfo):\n",
    "    topics: list[Topic] = info.context.get(\"topics\")  # type: ignore\n",
    "    topics_names = [topic.name for topic in topics]\n",
    "    if cls.topic not in topics_names:\n",
    "        raise ValueError(f\"Topic {cls.topic} not found in topics\")\n",
    "    topic = next(topic for topic in topics if topic.name == cls.topic)\n",
    "    if cls.subtopic not in [subtopic.name for subtopic in topic.subtopics]:\n",
    "        raise ValueError(f\"Subtopic {cls.subtopic} not found in Topic: {cls.topic}\")\n",
    "    return cls\n",
    "\n",
    "\n",
    "class Question(BaseModel):\n",
    "    id: str\n",
    "    problem: str\n",
    "    solution: str\n",
    "\n",
    "\n",
    "class TopicSubtopic(BaseModel):\n",
    "    topic: str\n",
    "    subtopic: str\n",
    "\n",
    "    @model_validator(mode=\"after\")  # type: ignore\n",
    "    def validate_topic_subtopic(self, info: ValidationInfo) -> \"TopicSubtopic\":\n",
    "        return validate_topic_subtopic(self, info)\n",
    "\n",
    "\n",
    "class QuestionWithTopicSubtopic(Question):\n",
    "    topic: str\n",
    "    subtopic: str\n",
    "\n",
    "    @model_validator(mode=\"after\")  # type: ignore\n",
    "    def validate_topic_subtopic(\n",
    "        self, info: ValidationInfo\n",
    "    ) -> \"QuestionWithTopicSubtopic\":\n",
    "        return validate_topic_subtopic(self, info)\n",
    "\n",
    "\n",
    "class QuestionsWithTopicSubtopic(BaseModel):\n",
    "    questions: list[QuestionWithTopicSubtopic] = Field(..., min_length=3, max_length=4)\n",
    "\n",
    "\n",
    "class QuestionWithTopicSubtopicAndSubquestions(QuestionWithTopicSubtopic):\n",
    "    subquestions: list[QuestionWithTopicSubtopic]\n",
    "\n",
    "\n",
    "class Concept(BaseModel):\n",
    "    concept: Annotated[\n",
    "        str,\n",
    "        AfterValidator(\n",
    "            partial(\n",
    "                validate_word_count, word_count=CONCEPT_WORD_COUNT, text_name=\"Concept\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "class QuestionWithConcept(QuestionWithTopicSubtopic):\n",
    "    concept: str\n",
    "\n",
    "\n",
    "class QuestionWithTopicSubtopicAndConceptSubquestions(QuestionWithTopicSubtopic):\n",
    "    subquestions: list[QuestionWithConcept]\n",
    "\n",
    "\n",
    "class QuestionWithConceptAndSubquestions(QuestionWithConcept):\n",
    "    subquestions: list[QuestionWithConcept]\n",
    "\n",
    "\n",
    "class ConceptWithQuestionIDs(BaseModel):\n",
    "    concept: str\n",
    "    question_ids: list[str] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "class Subtopic(BaseModel):\n",
    "    name: str\n",
    "    concepts: list[ConceptWithQuestionIDs] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "class Topic(BaseModel):\n",
    "    name: str\n",
    "    subtopics: list[Subtopic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def topics_str(topics: list[Topic]) -> str:\n",
    "    return deindent(\n",
    "        f\"\"\"\n",
    "TOPICS:\n",
    "\n",
    "{json.dumps([topic.model_dump() for topic in topics], indent=2)}\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def topic_subtopic_message(topics: list[Topic]) -> str:\n",
    "    return deindent(\n",
    "        f\"\"\"\n",
    "You are a world class math course instructor.\n",
    "You will be given a question with a 'problem' and a 'solution'.\n",
    "Given these topics and subtopics below, assign a 'topic' and a 'subtopic' to the question.\n",
    "The 'subtopic' must be one of the subtopics of the 'topic'.\n",
    "\n",
    "{topics_str(topics)}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def subqs_message(topics: list[Topic], book_pages: str = \"\") -> str:\n",
    "    prompt = deindent(\n",
    "        \"\"\"\n",
    "You are a world class math course instructor.\n",
    "You will be given a question with a 'problem', a 'solution', a 'topic', and a 'subtopic'.\n",
    "Based on the main question's problem and solution, break the question down into 3-4 smaller subquestions.\n",
    "Answering these questions in sequence should lead to the solution of the main question.\n",
    "Make sure that the answer to the last subquestion is the solution to the main question.\n",
    "So the subquestions are basically the steps to solve the main question.\n",
    "And if a student can solve the main question, we can assume that they have learned the underlying concepts of the subquestions.\n",
    "No 2 subquestions can have the same concept.\n",
    "For each subquestion:\n",
    "    1. Define the 'problem'.\n",
    "    2. Give a detailed 'solution'.\n",
    "    3. Given these topics below, assign a 'topic' and a 'subtopic' to the subquestion.\n",
    "       The 'subtopic' must be one of the subtopics of the 'topic'.\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    if book_pages:\n",
    "        prompt += f\"\\nYou can use these book pages for reference:\\n\\n{book_pages}\"\n",
    "    return prompt + f\"\\n\\n{topics_str(topics)}\"\n",
    "\n",
    "\n",
    "def concepts_str(concepts: list[str]) -> str:\n",
    "    return deindent(\n",
    "        f\"\"\"\n",
    "You can use a concept from the list below or come up with a new one if needed.\n",
    "\n",
    "CONCEPTS:\n",
    "\n",
    "{json.dumps(concepts, indent=2)}\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def question_w_concept_message(concepts: list[str]) -> str:\n",
    "    prompt = deindent(\n",
    "        f\"\"\"\n",
    "You are a world class math course instructor.\n",
    "You will be given a question with a 'problem', a 'solution', a 'topic', and a 'subtopic'.\n",
    "Assign a 'concept' to the question. The 'concept' should have at least {CONCEPT_WORD_COUNT} words.\n",
    "Solving this question should help students understand this concept.\n",
    "\"\"\"\n",
    "    )\n",
    "    if len(concepts) > 0:\n",
    "        prompt += concepts_str(concepts)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def question_w_subqs_concept_message(concepts: list[str]) -> str:\n",
    "    prompt = deindent(\n",
    "        f\"\"\"\n",
    "You are a world class math course instructor.\n",
    "You will be given a question with a 'problem', a 'solution', a 'topic', and a 'subtopic'.\n",
    "It will also have 3-5 subquestions. Each subquestion will have a 'problem', a 'solution', a 'topic', a 'subtopic', and a 'concept'.\n",
    "Based on the subquestions, assign a 'concept' to the main question. The 'concept' should have at least {CONCEPT_WORD_COUNT} words.\n",
    "Try not to repeat the concepts of the subquestions. Because the subquestions are the steps to solve the main question.\n",
    "Solving this question should help students understand this concept.\n",
    "\"\"\"\n",
    "    )\n",
    "    if len(concepts) > 0:\n",
    "        prompt += concepts_str(concepts)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def create_question_w_topic_subtopic(\n",
    "    question: Question, topics: list[Topic], model: ModelName = MODEL, attempts: int = 1\n",
    ") -> QuestionWithTopicSubtopic:\n",
    "    question_message = deindent(f\"Question:\\n\\n{question.model_dump_json(indent=2)}\")\n",
    "    ask_kwargs = dict(\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        model=model,\n",
    "        response_model=TopicSubtopic,\n",
    "        max_retries=attempts,\n",
    "        validation_context={\"topics\": topics},\n",
    "    )\n",
    "    if model in [ModelName.HAIKU, ModelName.SONNET, ModelName.OPUS]:\n",
    "        question_topic_subtopic = ask_cld.create(\n",
    "            system=topic_subtopic_message(topics),\n",
    "            messages=[\n",
    "                user_message(content=question_message),  # type: ignore\n",
    "            ],\n",
    "            **ask_kwargs,  # type: ignore\n",
    "        )\n",
    "    else:\n",
    "        question_topic_subtopic = ask_oai.create(\n",
    "            messages=[\n",
    "                system_message(topic_subtopic_message(topics)),\n",
    "                user_message(content=question_message),  # type: ignore\n",
    "            ],\n",
    "            **ask_kwargs,  # type: ignore\n",
    "        )\n",
    "    return QuestionWithTopicSubtopic.model_construct(\n",
    "        **question.model_dump(), **question_topic_subtopic.model_dump()\n",
    "    )\n",
    "\n",
    "\n",
    "def create_subquestions_w_topic_subtopic(\n",
    "    question_w_topic_subtopic: QuestionWithTopicSubtopic,\n",
    "    topics: list[Topic],\n",
    "    model: ModelName = MODEL,\n",
    "    attempts: int = 1,\n",
    "    pdf_collection: ChromaCollection | None = None,\n",
    "    n_results: int = 3,\n",
    "    n_next_links: int = 2,\n",
    "    n_prev_links: int = 2,\n",
    ") -> QuestionsWithTopicSubtopic:\n",
    "    book_pages = \"\"\n",
    "    if pdf_collection is not None:\n",
    "        question_res, _ = query_collection(\n",
    "            query_text=question_w_topic_subtopic.model_dump_json(\n",
    "                exclude={\"id\"}, indent=2\n",
    "            ),\n",
    "            collection=pdf_collection,\n",
    "            n_results=n_results,\n",
    "            n_next_links=n_next_links,\n",
    "            n_prev_links=n_prev_links,\n",
    "        )\n",
    "        book_pages = \"\\n\\n\".join([\"\\n\".join(res[\"documents\"]) for res in question_res])  # type: ignore\n",
    "    question_w_topic_subtopic_message = deindent(\n",
    "        f\"Question with Topic and Subtopic:\\n\\n{question_w_topic_subtopic.model_dump_json(indent=2)}\"  # type: ignore\n",
    "    )\n",
    "    sys_message = subqs_message(topics=topics, book_pages=book_pages)\n",
    "    ask_kwargs = dict(\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        model=model,\n",
    "        response_model=QuestionsWithTopicSubtopic,\n",
    "        max_retries=attempts,\n",
    "        validation_context={\"topics\": topics},\n",
    "    )\n",
    "    # print(f\"SYSTEM MESSAGE:\\n\\n{sys_message}\\n\\n\")\n",
    "    if model in [ModelName.HAIKU, ModelName.SONNET, ModelName.OPUS]:\n",
    "        return ask_cld.create(\n",
    "            system=sys_message,\n",
    "            messages=[user_message(content=question_w_topic_subtopic_message)],  # type: ignore\n",
    "            **ask_kwargs,  # type: ignore\n",
    "        )\n",
    "    else:\n",
    "        return ask_oai.create(\n",
    "            messages=[\n",
    "                system_message(sys_message),\n",
    "                user_message(content=question_w_topic_subtopic_message),  # type: ignore\n",
    "            ],\n",
    "            **ask_kwargs,  # type: ignore\n",
    "        )\n",
    "\n",
    "\n",
    "def get_topic_subtopic_from_question(\n",
    "    question: QuestionWithTopicSubtopic, topics: list[Topic]\n",
    ") -> tuple[Topic, Subtopic, int, int]:\n",
    "    topic_id, topic = next(\n",
    "        (i, topic) for i, topic in enumerate(topics) if topic.name == question.topic\n",
    "    )\n",
    "    subtopic_id, subtopic = next(\n",
    "        (i, subtopic)\n",
    "        for i, subtopic in enumerate(topic.subtopics)\n",
    "        if subtopic.name == question.subtopic\n",
    "    )\n",
    "    return topic, subtopic, topic_id, subtopic_id\n",
    "\n",
    "\n",
    "def create_subquestions_concepts(\n",
    "    subquestions: QuestionsWithTopicSubtopic,\n",
    "    topics: list[Topic],\n",
    "    model: ModelName = MODEL,\n",
    "    attempts: int = 1,\n",
    ") -> tuple[list[QuestionWithConcept], list[Topic]]:\n",
    "    subquestions_concepts = []\n",
    "    for subquestion_idx, subquestion in enumerate(subquestions.questions):\n",
    "        _, subtopic, topic_id, subtopic_id = get_topic_subtopic_from_question(\n",
    "            subquestion, topics\n",
    "        )\n",
    "        subtopic_concepts = [c.concept for c in subtopic.concepts]\n",
    "        # print(f\"{subtopic.model_dump_json(indent=2)}\\n\\n\")\n",
    "        concept_prompt = question_w_concept_message(concepts=subtopic_concepts)\n",
    "        subquestion_message = deindent(\n",
    "            f\"Question:\\n\\n{subquestion.model_dump_json(indent=2)}\"\n",
    "        )\n",
    "        try:\n",
    "            for attempt in Retrying(\n",
    "                wait=wait_random_exponential(min=30, max=60), stop=stop_after_attempt(3)\n",
    "            ):\n",
    "                with attempt:\n",
    "                    ask_kwargs = dict(\n",
    "                        max_tokens=MAX_TOKENS,\n",
    "                        model=model,\n",
    "                        response_model=Concept,  # type: ignore\n",
    "                        max_retries=attempts,\n",
    "                        validation_context={\"topics\": topics},\n",
    "                    )\n",
    "                    if model in [ModelName.HAIKU, ModelName.SONNET, ModelName.OPUS]:\n",
    "                        subquestion_concept = ask_cld.create(\n",
    "                            system=concept_prompt,\n",
    "                            messages=[user_message(content=subquestion_message)],  # type: ignore\n",
    "                            **ask_kwargs,  # type: ignore\n",
    "                        ).concept\n",
    "                    else:\n",
    "                        subquestion_concept = ask_oai.create(\n",
    "                            messages=[\n",
    "                                system_message(concept_prompt),\n",
    "                                user_message(content=subquestion_message),  # type: ignore\n",
    "                            ],\n",
    "                            **ask_kwargs,  # type: ignore\n",
    "                        ).concept\n",
    "            subquestions_concepts.append(subquestion_concept)\n",
    "            if subquestion_concept not in subtopic_concepts:\n",
    "                subtopic.concepts.append(\n",
    "                    ConceptWithQuestionIDs(concept=subquestion_concept)\n",
    "                )\n",
    "            topics[topic_id].subtopics[subtopic_id] = subtopic\n",
    "        except RetryError as e:\n",
    "            print(f\"Failed to generate concept for subquestion: {subquestion_idx}: {e}\")\n",
    "            continue\n",
    "    subquestions_w_concepts = [\n",
    "        QuestionWithConcept.model_construct(**subquestion.model_dump(), concept=concept)\n",
    "        for subquestion, concept in zip(subquestions.questions, subquestions_concepts)\n",
    "    ]\n",
    "    return subquestions_w_concepts, topics\n",
    "\n",
    "\n",
    "def construct_question_w_topic_subtopic_and_subquestions_w_concepts(\n",
    "    question_w_topic_subtopic: QuestionWithTopicSubtopic,\n",
    "    subquestions_w_concepts: list[QuestionWithConcept],\n",
    ") -> QuestionWithTopicSubtopicAndConceptSubquestions:\n",
    "    return QuestionWithTopicSubtopicAndConceptSubquestions.model_construct(\n",
    "        **question_w_topic_subtopic.model_dump(), subquestions=subquestions_w_concepts\n",
    "    )\n",
    "\n",
    "\n",
    "def create_question_w_concept_and_subquestions(\n",
    "    question: QuestionWithTopicSubtopicAndConceptSubquestions,\n",
    "    topics: list[Topic],\n",
    "    model: ModelName = MODEL,\n",
    "    attempts: int = 1,\n",
    ") -> QuestionWithConceptAndSubquestions:\n",
    "    subtopic = get_topic_subtopic_from_question(question, topics)[1]\n",
    "    subtopic_concepts = [c.concept for c in subtopic.concepts]\n",
    "    concept_prompt = question_w_subqs_concept_message(concepts=subtopic_concepts)\n",
    "    question_message = deindent(\n",
    "        f\"Question with Subquestions:\\n\\n{question.model_dump_json(indent=2)}\"\n",
    "    )\n",
    "    ask_kwargs = dict(\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        model=model,\n",
    "        response_model=Concept,\n",
    "        max_retries=attempts,\n",
    "        validation_context={\"topics\": topics},\n",
    "    )\n",
    "    if model in [ModelName.HAIKU, ModelName.SONNET, ModelName.OPUS]:\n",
    "        question_concept = ask_cld.create(\n",
    "            system=concept_prompt,\n",
    "            messages=[user_message(content=question_message)],  # type: ignore\n",
    "            **ask_kwargs,  # type: ignore\n",
    "        ).concept\n",
    "    else:\n",
    "        question_concept = ask_oai.create(\n",
    "            messages=[\n",
    "                system_message(concept_prompt),\n",
    "                user_message(content=question_message),  # type: ignore\n",
    "            ],\n",
    "            **ask_kwargs,  # type: ignore\n",
    "        ).concept\n",
    "    return QuestionWithConceptAndSubquestions.model_construct(\n",
    "        **question.model_dump(exclude={\"subquestions\"}),\n",
    "        concept=question_concept,\n",
    "        subquestions=question.subquestions,\n",
    "    )\n",
    "\n",
    "\n",
    "def update_topic_subtopic_concepts(\n",
    "    question: QuestionWithConceptAndSubquestions, topics: list[Topic]\n",
    ") -> list[Topic]:\n",
    "    _, subtopic, topic_id, subtopic_id = get_topic_subtopic_from_question(\n",
    "        question, topics\n",
    "    )\n",
    "    subtopic_concepts = [c.concept for c in subtopic.concepts]\n",
    "    if question.concept not in subtopic_concepts:\n",
    "        subtopic.concepts.append(\n",
    "            ConceptWithQuestionIDs(\n",
    "                concept=question.concept,\n",
    "                question_ids=[question.id],\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        subtopic.concepts[\n",
    "            subtopic_concepts.index(question.concept)\n",
    "        ].question_ids.append(question.id)\n",
    "    topics[topic_id].subtopics[subtopic_id] = subtopic\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "pdf_file = \"/media/hamza/data2/algebra.pdf\"\n",
    "collection_name = \"algebra_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# pdf_collection = pdf_to_collection(\n",
    "#     pdf_file,\n",
    "#     collection_name=collection_name,\n",
    "#     chunk_size=4000,\n",
    "#     chunk_overlap=200,\n",
    "#     device=\"cuda\",\n",
    "#     delete_existing=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "pdf_collection = chroma_collection(name=collection_name, delete_existing=False)\n",
    "pdf_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "topics = json.load(open(\"math_102_topics.json\"))\n",
    "topics = [\n",
    "    Topic(\n",
    "        name=topic[\"name\"],\n",
    "        subtopics=[Subtopic(name=subtopic) for subtopic in topic[\"subtopics\"]],\n",
    "    )\n",
    "    for topic in topics\n",
    "]\n",
    "topics[0].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "questions_dir = Path(\"math_102_questions\")\n",
    "questions = [\n",
    "    Question(**json.loads(question_file.read_text()))\n",
    "    for folder in questions_dir.iterdir()\n",
    "    for question_file in list(folder.glob(\"*.json\"))[:QUESTIONS_PER_FOLDER]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "final_dir = Path(\"math_102_final_questions\")\n",
    "os.makedirs(final_dir, exist_ok=True)\n",
    "final_topics = Path(\"math_102_final_topics.json\")\n",
    "missed_questions = []\n",
    "for i, question in enumerate(questions):\n",
    "    current_ids = [int(q.stem) for q in final_dir.glob(\"*.json\")]\n",
    "    if int(question.id) not in current_ids:\n",
    "        try:\n",
    "            question = create_question_w_topic_subtopic(\n",
    "                question=question,\n",
    "                topics=topics,\n",
    "                attempts=ATTEMPTS,\n",
    "                model=ModelName.GPT_3,\n",
    "            )\n",
    "            subquestions = create_subquestions_w_topic_subtopic(\n",
    "                question_w_topic_subtopic=question,\n",
    "                topics=topics,\n",
    "                attempts=ATTEMPTS,\n",
    "                pdf_collection=pdf_collection,\n",
    "                model=ModelName.GPT_4,\n",
    "            )\n",
    "            subquestions, topics = create_subquestions_concepts(\n",
    "                subquestions=subquestions,\n",
    "                topics=topics,\n",
    "                attempts=ATTEMPTS,\n",
    "                model=ModelName.GPT_3,\n",
    "            )\n",
    "            question = construct_question_w_topic_subtopic_and_subquestions_w_concepts(\n",
    "                question_w_topic_subtopic=question, subquestions_w_concepts=subquestions\n",
    "            )\n",
    "            question = create_question_w_concept_and_subquestions(\n",
    "                question=question,\n",
    "                topics=topics,\n",
    "                attempts=ATTEMPTS,\n",
    "                model=ModelName.GPT_3,\n",
    "            )\n",
    "            topics = update_topic_subtopic_concepts(question=question, topics=topics)\n",
    "            dest = final_dir / f\"{question.id}.json\"\n",
    "            with open(dest, \"w\") as f:\n",
    "                json.dump(question.model_dump(), f, indent=2)\n",
    "            with open(final_topics, \"w\") as f:\n",
    "                json.dump(\n",
    "                    [topic.model_dump() for topic in topics],\n",
    "                    f,\n",
    "                    indent=2,\n",
    "                )\n",
    "        except Exception as e:\n",
    "            missed_questions.append([i, e])\n",
    "            print(f\"Failed to generate question: {i}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
